# BUILD series s04 part p02
spack:
  # CUSTOM MODULES
  # these modifications blacklist the system compiler to make Core packages
  # this streamlines the lmod tree that we expose to the users
  modules: &modules
    # dev: figure out why we must use default
    # see note below. we use the default section instead of an lmod section since many different 
    #   modifications do not appear to work otherwise
    default:
      roots:
        lmod: ./lmod
      arch_folder: false
      lmod:
        hierarchy:
          # note that it would be nice to use Python here but only virtual packages are allowed
          - compiler
          - mpi
        core_compilers:
        - &gcc-back !system_compiler
        # see: https://spack.readthedocs.io/en/latest/module_file_support.html\
        #   #blacklist-or-whitelist-specific-module-files
        whitelist:
        - gcc
        blacklist:
        - !spec {'compiler': *gcc-back}
        core_compilers:
        - *gcc-back
        core_specs:
        # use projections and "osp modules" to move items set aside in core_specs to special locations
        #   in order to simplify the moduletree. note that you should NOT place openmpi here. spack will
        #   put the openmpi items in a special location that osp modules will detect and relocate
        # dev: we must identify python-openmpi dependencies by name for now. better to be systematic
        - py-numpy
        # we identify all python packages by build, except for pip and setuptools. this ensures these end
        #   up in specific projections under Core which are then easy to move with osp modules
        - build_system=python_pip
        - py-pip
        - py-setuptools
        # the folllowing items (hash_length, blacklist_implicits, etc) do not work above in the lmod
        #   section. instead they must be placed here in the default section
        #  dev: figure out why we have to place it in defaults
        hash_length: 0
        blacklist_implicits: true
        projections:
          # we must select projections carefully in sync with core_specs. the projections before "all" will
          #   tell spack where to put modulefiles. we use core_specs to put all of the modules that we want
          #   to move around in an easy to detect location with a specific projection. the osp modules 
          #   function will detect these naming conventions. 
          # dev: it would be better to be programmatic and use a merge key (i.e. "<< :"), or some kind of yaml 
          #   variable shennanigans in which we try to avoid repeating the targets, to concatenate a list
          #   or perhaps a yaml tag to populate the python and MPI-dependent python packages. for now we
          #   are hardcoding them so that they are distinguished from the packages which might only be
          #   dependent on python and not also MPI. note that rbradley links spaces in the projections key,
          #   which should be a spec, might indicate an OR operation and not an intersection or AND operation
          #   which is very confusing. this needs investigated further
          # do not include MPI on this list. let spack put them in place and osp modules will detect them
          #   despite the addition of a hash
          # dev: the osp modules command is only set up to handle one of each MPI right now. it drops the
          #   associated hash. we could probably find a way to retain it if we need multiple MPI of the same
          #   version number. but this seems like a niche use-case. our openmpi items are handled by "all"
          # we must play a trick to isolate the mpi-dependent Python packages, for example py-numpy, so we 
          #   use the dependence on python_pip as the distinguishing feature
          py-numpy: &py-mpi-pro 'py-{^python.version}-{compiler.name}-{compiler.version}-{^mpi.name}-{^mpi.version}/{name}/{version}'
          build_system=python_pip: &py-pro 'py-{^python.version}-{compiler.name}-{compiler.version}/{name}/{version}' 
          py-pip: *py-pro
          py-setuptools: *py-pro
          ^r: 'r-{^r.version}/{name}/{version}'
          all: '{name}/{version}'
  # EXTERNAL packages
  packages:
    intel:
      buildable: false
      externals:
      - prefix: /cm/shared/apps/Intel/2022/
        spec: !spec {name: intel-oneapi-compilers@2022.1.0, compiler: *gcc-back}
    slurm:
      buildable: false
      externals:
      - prefix: /cm/shared/apps/slurm/current
        spec: slurm@20-11-9-1
  concretizer:
    # unify true was formerly concretize together
    # docs recommend false for HPC groups, see https://spack.readthedocs.io/en/latest/environments.html
    unify: false
    reuse: true
  # note that software in this superspec is built for spack v0.19
  specs: !flatten
  # compiler: gcc 12
  - - - &gcc12 !cat
        - gcc@12.2.0
        - arch=linux-centos8-skylake_avx512
        - !spec {compiler: *gcc-back}
  - &gcc-all
    # packages compiled with gcc 12
    - !compiled
      compiler: *gcc12
      specs: !flatten
      - &gcc-specs
        - git
        - cuda@11.1.0 +dev
        - cmake@3.22.1 
      # pythons
      - - &py3108 !cat 
          - python@3.10.8 
          - &pybase +bz2 +ctypes +dbm ~debug +libxml2 +lzma ~nis +optimizations +pic
            +pyexpat +pythoncmd +readline +shared +sqlite3 +ssl ~tix ~tkinter ~ucs4 +uuid +zlib
        # R
        - &r422 !cat
          - r@4.2.2
          - !spec {depends: *py3108}
      # openblas
      - - &blas0319 !cat
          - openblas@0.3.19
          - &blas-variants ~bignuma ~consistent_fpcsr +ilp64 +locking +pic +shared   
      # OTHERS
      #! dev: failing below for various reasons
      #! - - !cat
      #!     - julia@1.7.2
      #!     - !spec {depends: *py3108}  
      #!     - !spec {depends: 'llvm@12.0.1 targets=bpf,webassembly'}  
      #!     # removed amdgpu from the targets list manually because the above didn't take
      #!     # julia rolls its own openblas because we cannot match it due to some suffix problem
      #!     # beware that we need an llvm for julia so we might want to make a centralized one,
      #!     # however there are targets we might want to restrict:
      #!     #   targets=amdgpu,bpf,nvptx,webassembly
    # mpi: openmpi 4
    - - &ompi4 !cat
        - &ompi4-base !cat
          - openmpi@4.1.2
          # see modification to spack source with a path change to solve the perpetual problem
          #   of not finding infiniband include files: env.prepend_path('CPATH','/usr/include/infiniband/')
          - &ompi-variants +atomics ~cuda ~cxx ~cxx_exceptions ~gpfs ~internal-hwloc ~java +legacylaunchers
            ~lustre ~memchecker +pmi +romio +rsh ~singularity 
            fabrics=hcoll,ucx,ofi,cma schedulers=slurm
          # note significant tuning in this section to achieve the correct performance, see the
          #   development notes for series s04 in the overspack/README.md
          # previously struggled with a seeming circular dependency in which numpy with MKL with the
          #   cluster option used openmpi which depended on rdma-core and py-docutils, but this was
          #   somehow resolved by pinning against the right setuptools, so it might have been a numpy 
          #   issue. still not even sure what caused the problem, but the superspec works
        - !spec {depends: ucx +verbs +cma +dc +dm +knem +mlx5_dv +openmp +rdmacm +thread_multiple +ud}
        - !spec {depends: slurm +pmix}
        - !spec {depends: &libfabric 'libfabric fabrics=tcp,verbs,udp,shm,rxd,rxm'}
        - !spec {compiler: *gcc12}
    - - &intel-oneapi-mkl !cat
        - &intel-oneapi-mkl-base intel-oneapi-mkl +cluster ~ilp64 +shared ^intel-oneapi-tbb 
        - !spec {depends: *ompi4}
    # openmpi-dependent packages
    - !loop_depends
      base: *ompi4
      specs:
      - !cat
        - hdf5@1.12.1
        - &hdf5-base +cxx +fortran +mpi +shared +hl +szip +tools
      - !cat 
        - fftw@3.3.10
        - &fftw-base +mpi +openmp ~pfft_patches precision=double,float
    # packages compiled for python 3.10.8
    - !loop_depends
      base: *py3108
      specs: &py-mods-compiled
      - &pysetup py-setuptools@59.4.0
      - py-wheel
      - py-pip
      - &py-cython !cat [py-cython, !spec {depends: *pysetup}]
      # note that py-numpy should use MKL over openblas for performance on intel systems. 
      # note that we previously got lots of "cannot depend twice" errors, see
      #   https://github.com/spack/spack/issues/19782 
      # however, spack should be able to handle multiple distinct hashes on an upstream dependency that
      #   appears on multiple branches on the tree, since probably version v0.17
      # dev: we had to pin setuptools here to avoid an error in which it tried to use two separate version,
      #   however rbradley never found a good reason for why. perhaps easier to answer after more practice
      - !cat 
        - py-numpy +blas +lapack
        - !spec {depends: *intel-oneapi-mkl}
        - !spec {depends: *py3108}
        - !spec {depends: *pysetup}
#!    # packages depends on openblas
#!    - !loop_depends
#!      base: *blas0319
#!      specs:
#!      - gsl@2.7 
#!    # packages exclusive to python 3.9.9
#!    - !loop_depends
#!      # we have to be more explicit with the compiler or spack defaults to gcc-back
#!      base: !cat [*py3108, !spec {compiler: *gcc12}]
#!      specs:
#!      - snakemake +reports
#!    # packages compiled for Python 3.8.12
#!    - !loop_depends
#!      base: !cat [*py3812, !spec {compiler: *gcc12}]
#!      specs: *py-mods-compiled
#!    # packages compiled for R 4.1.2
#!    #! r-irkernel is failing due to issues with llvm which supports it
#!    #! - !loop_depends
#!    #!   # note that R depends on Python above which manages redundancy
#!    #!   base: *r422
#!    #!   specs: &r-packages
#!    #!     - r-irkernel
#!  
